{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Song_name</th>\n",
       "      <th>type</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>नीले नीले अम्बर पर</td>\n",
       "      <td>romantic</td>\n",
       "      <td>किशोर कुमार</td>\n",
       "      <td>नीले नीले अम्बर चाँद प्यार बरस तरस नीले नीले अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>अक्कड़ बक्कड़</td>\n",
       "      <td>party</td>\n",
       "      <td>बादशाह</td>\n",
       "      <td>अक्कड़ बक्कड़ बॉम्बे बो पुरे रात बज पौ अक्कड़ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>अखियाँ</td>\n",
       "      <td>sad</td>\n",
       "      <td>पोपोन</td>\n",
       "      <td>थक गेया अँख जग्ग दिय अख माह ना लभद अँखियाँहाये...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>अंग से अंग लगाना</td>\n",
       "      <td>romantic</td>\n",
       "      <td>अलका याग्निक, बिनोद राठौड़, सुदेश भोसले</td>\n",
       "      <td>आए आए चाहो बाँहो भर अंग अंग लग सजन रंग लग अंग ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>अगर ज़िन्दगी हो</td>\n",
       "      <td>romantic</td>\n",
       "      <td>आशा भोसले</td>\n",
       "      <td>ज़िन्दगी संग ज़िन्दगी संग मौत मौत ज़िन्दगी संग...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            Song_name      type  \\\n",
       "0      1   नीले नीले अम्बर पर  romantic   \n",
       "1      2        अक्कड़ बक्कड़     party   \n",
       "2      3               अखियाँ       sad   \n",
       "3      4     अंग से अंग लगाना  romantic   \n",
       "4      5      अगर ज़िन्दगी हो  romantic   \n",
       "\n",
       "                                    artist  \\\n",
       "0                              किशोर कुमार   \n",
       "1                                   बादशाह   \n",
       "2                                    पोपोन   \n",
       "3  अलका याग्निक, बिनोद राठौड़, सुदेश भोसले   \n",
       "4                                आशा भोसले   \n",
       "\n",
       "                                              lyrics  \n",
       "0  नीले नीले अम्बर चाँद प्यार बरस तरस नीले नीले अ...  \n",
       "1  अक्कड़ बक्कड़ बॉम्बे बो पुरे रात बज पौ अक्कड़ ...  \n",
       "2  थक गेया अँख जग्ग दिय अख माह ना लभद अँखियाँहाये...  \n",
       "3  आए आए चाहो बाँहो भर अंग अंग लग सजन रंग लग अंग ...  \n",
       "4  ज़िन्दगी संग ज़िन्दगी संग मौत मौत ज़िन्दगी संग...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset\n",
    "df = pd.read_csv(\"Data\\songs_without_stopwords.csv\", low_memory=False)   \n",
    "#df = pd.read_csv(\"binary.csv\", low_memory=False) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define features andtags and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df.type\n",
    "x=df.lyrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2) # use random number generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, confusion_matrix\n\u001b[0;32m      8\u001b[0m rf \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mvect\u001b[39m\u001b[39m'\u001b[39m, CountVectorizer()),\n\u001b[0;32m      9\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m, TfidfTransformer()),\n\u001b[0;32m     10\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, \n\u001b[0;32m     11\u001b[0m                                                random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,class_weight \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m)),\n\u001b[0;32m     12\u001b[0m                ])\n\u001b[1;32m---> 14\u001b[0m rf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     16\u001b[0m y_pred \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     17\u001b[0m my_tags \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39msad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mromantic\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mparty\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#classify \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "rf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=150, max_depth=6, \n",
    "                                               random_state=0,class_weight = \"balanced\")),\n",
    "               ])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "my_tags = [\"sad\", \"romantic\",\"party\"]\n",
    "accuracy=accuracy_score(y_pred, y_test)*100\n",
    "print('accuracy %s' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     -------------------------------------- 293.3/293.3 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.3-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from seaborn) (1.24.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.4.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp39-cp39-win_amd64.whl (160 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dvipa\\onedrive\\desktop\\aaikyam\\song_database_creation\\crawler\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.6.3 pillow-9.4.0 pyparsing-3.0.9 seaborn-0.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m     \n\u001b[1;32m----> 5\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred, my_tags)\n\u001b[0;32m      6\u001b[0m ax\u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot()\n\u001b[0;32m      7\u001b[0m sns\u001b[39m.\u001b[39mheatmap(cm, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ax \u001b[39m=\u001b[39m ax); \u001b[39m#annot=True to annotate cells\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, my_tags)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(my_tags); ax.yaxis.set_ticklabels(my_tags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m song\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnter song name for which you want to classify  :\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m#series of both songname and lyrics\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m songlist\u001b[39m=\u001b[39my \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mSong_name\n\u001b[0;32m      8\u001b[0m lyric\u001b[39m=\u001b[39my \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mlyrics\n\u001b[0;32m      9\u001b[0m length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(lyric)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#CLASSIFICATION OF  SINGLE SONG\n",
    "\n",
    "#song=[]\n",
    "song=input('Enter song name for which you want to classify  :')\n",
    "\n",
    "#series of both songname and lyrics\n",
    "songlist=y = df.Song_name\n",
    "lyric=y = df.lyrics\n",
    "length=len(lyric)\n",
    "\n",
    "#converting both to ndarray\n",
    "sl=songlist.to_numpy()\n",
    "l=lyric.to_numpy()\n",
    "matched_index=0\n",
    "\n",
    "\n",
    "i=0\n",
    "#check for index of song\n",
    "while i < length:\n",
    "    if song == sl[i]:\n",
    "        matched_index=i\n",
    "    i += 1\n",
    "print(f'{song} is present in songlist at indexes {matched_index}')\n",
    "\n",
    "\n",
    "\n",
    "#fetching lyrics of that song\n",
    "lyrics=l[matched_index]\n",
    "#print(lyrics)\n",
    "\n",
    "#creating series from string\n",
    "list = [lyrics]\n",
    "ser = pd.Series(list)\n",
    "print(ser)\n",
    "\n",
    "#predicting mood of that song\n",
    "y_pred = rf.predict(ser)\n",
    "print(y_pred)\n",
    "\n",
    "#मिले हो तुम हमको\n",
    "#फर्स्ट क्लास\n",
    "#महरमा\n",
    "#हमनवा मेरे"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad']\n"
     ]
    }
   ],
   "source": [
    "lyric_pred='''दर्द का तेरे एहसास रहा है \n",
    "तेरा एहसास मेरे पास रहा है \n",
    "दर्द का तेरे एहसास रहा है \n",
    "तेरा एहसास मेरे पास रहा है \n",
    "एक तुझे बस मेरी लगन थी \n",
    "बात ये देर से समझ में है आयी '''\n",
    "daa=np.array([lyric_pred])\n",
    "ser=pd.Series(daa,index=[0])\n",
    "y_pred = rf.predict(ser)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m rf\n\u001b[0;32m      2\u001b[0m \u001b[39m# !pip install pickle5\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "model = rf\n",
    "# !pip install pickle5\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mmood_classification.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m pickle\u001b[39m.\u001b[39mdump(rf, \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "filename = (\"mood_classification.pkl\")\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romantic']\n"
     ]
    }
   ],
   "source": [
    "lyric_pred='''मीठी बातें करके\n",
    "साड़ी कुड़ियाँ ले गया\n",
    "वीरा वैनिला लॉ एंड\n",
    "मौका जब मिला ले\n",
    "होठों पे देके फवौर\n",
    "सदा चुम्मी ले गया\n",
    "यह भाई तेरी जवानी\n",
    "थे एन्ड हो गयी\n",
    "ओह तेरी साड़ी दीवानी\n",
    "सद्दी फ्रेंड हो गयी\n",
    "ोये दज न बुलवाडो\n",
    "बुलवाडो बलद्वाड़ा\n",
    "वादो वे '''\n",
    "daa=np.array([lyric_pred])\n",
    "ser=pd.Series(daa,index=[0])\n",
    "y_pred = loaded_model.predict(ser)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e884784e185f7d62f83ce5dc1499ac8abb64730328c963623e01dfa82efaea2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
